{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "naked-recruitment",
   "metadata": {},
   "source": [
    "# Fit PDF with conditional variable\n",
    "\n",
    "In this example, we show an unusual  fit where the total sample is not drawn form a single probability distribution, but each individual sample $x$ is drawn from a different distribution, whose parameters are determined by a conditional variable $y$.\n",
    "\n",
    "In our example, we are drawing samples $x$ from varying Gaussian distributions. The location of each Gaussian is a function of the conditional variable $y$, but all share the same width parameter $\\sigma$. We fit the shared parameter $\\sigma$, but also the parameters $a$ and $b$ which determine how the location of each gaussian depends on $y$, assuming a line function $\\mu = a + b y$.\n",
    "\n",
    "This tutorial reproduces a [corresponding one from RooFit](https://root.cern.ch/doc/master/rf303__conditional_8C.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "technological-economy",
   "metadata": {},
   "outputs": [],
   "source": [
    "import iminuit\n",
    "from iminuit.cost import UnbinnedNLL\n",
    "from iminuit import Minuit\n",
    "import numpy as np\n",
    "import numba as nb\n",
    "import boost_histogram as bh\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "from numba_stats import norm as norm_nb\n",
    "print(\"iminuit version\", iminuit.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wicked-animal",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(1)\n",
    "\n",
    "# conditional variable: each sample is paired with a random y parameter\n",
    "y = rng.normal(0, 10, size=10000)\n",
    "y = y[np.abs(y) < 10]  # truncate at 10\n",
    "\n",
    "# location of each gaussian is a function of y\n",
    "def mu(y, a, b):\n",
    "    return a + b * y\n",
    "\n",
    "# draw samples from Gaussians whose locations depend on y\n",
    "truth = {\"a\": 0, \"b\": 0.5, \"sigma\": 1.0}\n",
    "x = rng.normal(mu(y, truth[\"a\"], truth[\"b\"]), truth[\"sigma\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "removable-forward",
   "metadata": {},
   "source": [
    "The distribution in $x$ is more broad than the usual Gaussian because it is a convolution of many Gaussian distributions with varying means. We can visualise this by binning the data in $x$ and $y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subjective-sleep",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax_x = bh.axis.Regular(100, -10, 10)\n",
    "ax_y = bh.axis.Regular(5, -10, 10)\n",
    "h = bh.Histogram(ax_x, ax_y)\n",
    "h.fill(x, y)\n",
    "for i, (a, b) in enumerate(ax_y):\n",
    "    plt.stairs(h.values()[:,i], ax_x.edges, label=f\"[{a}, {b})\",\n",
    "               fill=True, alpha=0.2)\n",
    "h1 = h[:, sum]\n",
    "plt.stairs(h1.values(), ax_x.edges, color=\"k\", label=\"total\")\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"events\")\n",
    "plt.legend(title=\"y interval\", frameon=False, handlelength=1.2);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "copyrighted-plenty",
   "metadata": {},
   "source": [
    "## Fit with conditional variable\n",
    "\n",
    "The random distribution of $x$ depends on the value of $y$. We can exploit that information in the likelihood function to obtain a more accurate estimate of the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aware-fantasy",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(xy, a, b, sigma):\n",
    "    x, y = xy\n",
    "    mu = a + b * y\n",
    "    # cannot use norm.pdf from numba_stats here, because it is not vectorized in mu\n",
    "    return norm.pdf(x, mu, sigma)\n",
    "\n",
    "nll = UnbinnedNLL((x, y), model)\n",
    "\n",
    "m = Minuit(nll, 0.0, 0.0, 2.0)\n",
    "m.limits[\"sigma\"] = (0, None)\n",
    "m.migrad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aquatic-belgium",
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct model representation for comparison with data histogram\n",
    "a, b, sigma = m.values\n",
    "\n",
    "# get expected content per bin from cdf, sum over the individual cdfs\n",
    "v = np.diff(np.sum(norm.cdf(ax_x.edges[:,np.newaxis],\n",
    "                            mu(y, a, b), sigma), axis=1))\n",
    "\n",
    "plt.stairs(v, ax_x.edges, label=\"model\", zorder=5, lw=2)\n",
    "plt.errorbar(ax_x.centers, h1.values(), h1.variances() ** 0.5,\n",
    "             fmt=\"ok\", label=\"data\")\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"events\")\n",
    "plt.legend(frameon=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "integrated-listening",
   "metadata": {},
   "source": [
    "## Fit without conditional variable\n",
    "\n",
    "We can also ignore the dependence of $x$ and $y$ and just fit the total $x$ distribution with a model built from the distribution of $y$ values. This also works in this case, but information is lost and therefore the parameter uncertainties become larger than in the previous case.\n",
    "\n",
    "On top of that, the calculation is much slower, because building the pdf is more expensive. We parallelise the computation with numba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "protecting-monte",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb.config.THREADING_LAYER = 'workqueue'\n",
    "\n",
    "\n",
    "@nb.njit(parallel=True, fastmath=True)\n",
    "def model(x, a, b, sigma):\n",
    "    mu = a + b * y\n",
    "    total = np.zeros_like(x)\n",
    "    for i in nb.prange(len(mu)):\n",
    "        total += norm_nb.pdf(x, mu[i], sigma)\n",
    "    return total\n",
    "\n",
    "\n",
    "nll = UnbinnedNLL(x, model)\n",
    "m2 = Minuit(nll, 0.0, 0.0, 2.0)\n",
    "m2.limits[\"sigma\"] = (0, None)\n",
    "m2.migrad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "julian-border",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 3, figsize=(8, 2), constrained_layout=True)\n",
    "for par, axi in zip(m.parameters, ax):\n",
    "    axi.set_title(par)\n",
    "    t = truth[par]\n",
    "    axi.axhline(t, ls=\"--\", color=\"0.5\")\n",
    "    axi.errorbar([\"with\\n conditional\"], m.values[par],\n",
    "                 m.errors[par], fmt=\"ok\")\n",
    "    axi.errorbar([\"without\\n conditional\"], m2.values[par],\n",
    "                 m2.errors[par], fmt=\"or\")\n",
    "    axi.set_xlim(-0.5, 1.5)\n",
    "    dt = 2 * m2.errors[par]\n",
    "    axi.set_ylim(t - dt, t + dt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.14 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "python3",
   "version": "3.9.14"
  },
  "vscode": {
   "interpreter": {
    "hash": "bdbf20ff2e92a3ae3002db8b02bd1dd1b287e934c884beb29a73dced9dbd0fa3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
